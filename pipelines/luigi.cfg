#################################
###### 		SET UP		   ######
#################################
[core]
#logging_conf_file=./logging.cfg
default-scheduler-host:localhost
default-scheduler-port:8082

[DEFAULT]
raw_bucket = s3://dpa-plataforma-preventiva/etl/
local_path = ../data/
bash_scripts = ./ingest/bash_scripts
python_scripts = ./ingest/python_scripts/
extra_parameters = 

#################################
###### Pipelines Schemas ######
#################################

[Runpipelines]	
raw_schema: raw
clean_schema: clean
temp: ../data/temp

[Ingestpipeline]
pipelines: sagarpa, sagarpa_cierre

# Available Pipelines: transparencia, sagarpa, banxico, sagarpa_cierre, segob, economia
# Define Parameters for each Pipeline in "Pipeline Parameters" >>


[classic_pipeline] # Pipeline for classic ingestion
s3bucket = dpa-plataforma-preventiva

[local_ingest]

[local_to_s3]


#################################
###### Pipeline Parameters ######
#################################
# General: if there are two or more parameters, those should be included 'extra_parameters'. If one of those is a start_date, it should be the first in extra_parameters. 

[transparencia]	
type_script = sh

[banxico]

[sagarpa]
extra_parameters: start_date, cultivo
start_date: 2017
cultivo: maiz-grano

[sagarpa_cierre]
extra_parameters: start_date, cultivo
start_date: 2016
cultivo: maiz-grano

[segob]

[economia]
#possible extra: end_date (granos/frutos)

#################################
######    Methods Tasks    ######
#################################

[RTask]

[PythonTask]

[PySparkTask]

[SqoopTask]

[HadoopTask]

[RawData]

