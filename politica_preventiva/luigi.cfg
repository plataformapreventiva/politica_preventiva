#################################
###### 		SET UP		   ######
#################################

[core]
logging_conf_file=./logging.cfg
default-scheduler-host:localhost
default-scheduler-port:8082
max-reschedules=4
max-shown-tasks=10
max-graph-nodes=100000
email-prefix: [LUIGI]
email-sender: r.sanchezavalos@gmail.com
error-email:  r.sanchezavalos@gmail.com
rpc-connect-timeout=100.0
timeout=4800

[DEFAULT]
raw_bucket = s3://dpa-plataforma-preventiva/etl/
spark_bucket = s3://dpa-plataforma-preventiva/utils/spark/
classic_task_scripts = ./pipelines/ingest/classic/source/
common_path  = ./pipelines/ingest/common/
local_path = /data/
historical = True


[postgres]
local-tmp-dir = /data

#################################
###### Pipelines INGEST ######
#################################

[Runpipelines]
raw_schema = raw
clean_schema =  clean
temp = ./data/temp


#################################
###### ClassicIngest       ######
#################################
[IngestPipeline]
pipelines = conagua_temperaturas

[IngestDates]

[UpdateLineage]

[UpdateDictionary]

[UpdateRawDB]

[Concatenation]

[Preprocess]

[LocalToS3]

[LocalIngest]

[RawHeaderTest]

[AddEmrStep]

#################################
###### Pipelines ETL ######
#################################

[ETLPipeline]
pipelines = ["coneval_municipios"]

[ETL]

[UpdateCleanDB]
clean_scripts = ./pipelines/etl/clean/

[UpdateTidyDB]
tidy_scripts = ./pipelines/etl/tidy/

#################################
###### Pipelines Semantic  ######
#################################

[SemanticPipeline]
semantics = coneval

[UpdateSemanticDB]
semantic_scripts = ./pipelines/semantic/scripts/

#################################
######    Methods Tasks    ######
#################################

[DockerTask]
[TDockerTask]
[PgRTask]
[EmrTask]
[InitializeCluster]
[PySparkTask]
